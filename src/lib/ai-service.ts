import { ApiConfig } from '@/components/ApiSettings'

// Semaphore class to limit concurrent requests
class Semaphore {
  private permits: number
  private waiting: Array<() => void> = []

  constructor(permits: number) {
    this.permits = permits
  }

  async acquire(): Promise<void> {
    if (this.permits > 0) {
      this.permits--
      return Promise.resolve()
    }

    return new Promise((resolve) => {
      this.waiting.push(resolve)
    })
  }

  release(): void {
    this.permits++
    if (this.waiting.length > 0) {
      const next = this.waiting.shift()
      if (next) {
        this.permits--
        next()
      }
    }
  }
}

export class AIService {
  private static instance: AIService
  private config: ApiConfig | null = null
  private semaphore = new Semaphore(2) // Limit to 2 concurrent requests

  private constructor() {}

  static getInstance(): AIService {
    if (!AIService.instance) {
      AIService.instance = new AIService()
    }
    return AIService.instance
  }

  setConfig(config: ApiConfig) {
    this.config = config
    console.log('AI Service config set:', {
      hasApiKey: !!config.apiKey,
      textModel: config.textModel,
      imageModel: config.imageModel
    })
  }

  async generateText(prompt: string, options?: {
    systemPrompt?: string
    temperature?: number
    maxTokens?: number
  }): Promise<string> {
    await this.semaphore.acquire()
    try {
      console.log('AI Service generateText called with:', { 
        hasConfig: !!this.config, 
        hasApiKey: !!this.config?.apiKey,
        hasSparkWindow: !!(window as any).spark,
        prompt: prompt.substring(0, 100) + '...'
      })

      // Always use Venice AI if configured, fallback to internal
      if (this.config?.apiKey) {
        console.log('Using Venice AI for text generation with model:', this.config.textModel)
        
        try {
          const messages: Array<{role: string, content: string}> = []
          if (options?.systemPrompt) {
            messages.push({ role: 'system', content: options.systemPrompt })
          }
          messages.push({ role: 'user', content: prompt })

          const requestBody: any = {
            model: this.config.textModel,
            messages,
            temperature: options?.temperature ?? 0.8,
            max_tokens: options?.maxTokens ?? 2000
          }
          
          // Venice AI doesn't support hide_reasoning parameter

          const response = await fetch('https://api.venice.ai/api/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${this.config.apiKey}`
            },
            body: JSON.stringify(requestBody)
          })

          if (!response.ok) {
            const errorText = await response.text()
            console.error('Venice AI text generation failed:', response.status, errorText)
            throw new Error(`Venice AI failed: ${response.status}`)
          }

          const data = await response.json()
          let result = data.choices?.[0]?.message?.content
          if (!result) {
            console.error('No content in Venice AI response:', data)
            throw new Error('No content generated by Venice AI')
          }
          
          // Filter out reasoning for reasoning models (only for specific models that show reasoning)
          const reasoningModels = ['deepseek-r1-671b', 'qwen-2.5-qwq-32b', 'qwen-2.5-qwq-32b-preview']
          if (reasoningModels.includes(this.config.textModel) && result.length > 100) {
            console.log('Applying reasoning filter for model:', this.config.textModel)
            
            // Look for common reasoning patterns at the start
            const reasoningPatterns = [
              /^<thinking>[\s\S]*?<\/thinking>\s*/i,
              /^<reasoning>[\s\S]*?<\/reasoning>\s*/i,
              /^I need to think about[\s\S]*?(?=\n\n|\n[A-Z][a-z])/i,
              /^Let me think[\s\S]*?(?=\n\n|\n[A-Z][a-z])/i,
              /^To approach this[\s\S]*?(?=\n\n|\n[A-Z][a-z])/i,
              /^First, I should[\s\S]*?(?=\n\n|\n[A-Z][a-z])/i
            ]
            
            let cleanedResult = result
            for (const pattern of reasoningPatterns) {
              const match = cleanedResult.match(pattern)
              if (match) {
                console.log('Found reasoning pattern, removing:', match[0].substring(0, 50) + '...')
                cleanedResult = cleanedResult.replace(pattern, '').trim()
                break // Only remove the first pattern found
              }
            }
            
            // If we removed reasoning content and there's still content left, use the cleaned version
            if (cleanedResult.length > 20 && cleanedResult !== result) {
              console.log('Reasoning filtered out, using cleaned content')
              result = cleanedResult
            } else if (cleanedResult.length <= 20) {
              console.log('Reasoning filter removed too much content, keeping original')
              // Keep original if we removed too much
            }
          }
          
          console.log('Venice AI generation successful')
          return result
        } catch (veniceError) {
          console.error('Venice AI error, falling back to internal:', veniceError)
          const errorMessage = veniceError.toString().toLowerCase()
          if (errorMessage.includes('401') || errorMessage.includes('unauthorized')) {
            throw new Error('Venice AI API key is invalid. Please check your API settings.')
          } else if (errorMessage.includes('400') || errorMessage.includes('bad request')) {
            console.log('Venice AI bad request, trying internal fallback...')
            // Continue to internal fallback
          } else {
            console.log('Venice AI error, trying internal fallback...')
            // Continue to internal fallback  
          }
        }
      }

      // Fallback to internal spark.llm
      console.log('Using internal AI for text generation')
      
      // Check if spark is available
      if (!(window as any).spark || !(window as any).spark.llm || !(window as any).spark.llmPrompt) {
        console.error('Spark AI not available:', {
          hasSpark: !!(window as any).spark,
          hasLlm: !!(window as any).spark?.llm,
          hasLlmPrompt: !!(window as any).spark?.llmPrompt
        })
        throw new Error('AI services not available. Please check your configuration.')
      }

      try {
        const fullPrompt = options?.systemPrompt 
          ? (window as any).spark.llmPrompt`${options.systemPrompt}\n\nUser: ${prompt}`
          : (window as any).spark.llmPrompt`${prompt}`
        
        console.log('Calling internal spark.llm with prompt')
        const result = await (window as any).spark.llm(fullPrompt)
        
        if (!result || typeof result !== 'string') {
          console.error('Invalid result from spark.llm:', typeof result, result)
          throw new Error('Invalid response from internal AI')
        }
        
        console.log('Internal AI generation successful')
        return result
      } catch (sparkError) {
        console.error('Internal AI error:', sparkError)
        const errorMessage = sparkError.toString().toLowerCase()
        if (errorMessage.includes('content_filter') || errorMessage.includes('responsibleai')) {
          throw new Error('Content was filtered by internal AI. Please configure Venice AI with an uncensored model for NSFW content.')
        }
        throw new Error('Failed to generate content with internal AI')
      }
    } catch (error) {
      console.error('AI Service generateText error:', error)
      throw error
    } finally {
      this.semaphore.release()
    }
  }

  async generateImage(prompt: string, options?: {
    width?: number
    height?: number
    style?: string
  }): Promise<string> {
    await this.semaphore.acquire()
    try {
      console.log('Starting Venice AI image generation for prompt:', prompt)
      
      if (!this.config?.apiKey) {
        console.log('No Venice AI API key configured - using placeholder')
        return this.generateAdvancedPlaceholder(prompt, options?.width || 400, options?.height || 400)
      }
      
      // Prepare clean prompt for Venice AI
      const cleanPrompt = prompt.replace(/[^\w\s,.!?-]/g, '').trim()
      const finalPrompt = `${cleanPrompt}, ${options?.style || 'photorealistic, high quality, detailed, professional portrait photography'}`
      console.log('Final prompt for Venice AI:', finalPrompt)
      console.log('Using Venice AI image model:', this.config.imageModel)
      
      // Use correct Venice AI image models based on their current API
      const validModels = [
        'venice-sd35',
        'flux-dev', 
        'flux-dev-uncensored',
        'hidream',
        'stable-diffusion-3.5',
        'lustify-sdxl',
        'pony-realism',
        'wai-Illustrious'
      ]
      
      const modelsToTry = [
        this.config.imageModel && validModels.includes(this.config.imageModel) ? this.config.imageModel : 'venice-sd35',
        'venice-sd35', // Always try default
        'flux-dev'
      ].filter((model, index, arr) => arr.indexOf(model) === index) // Remove duplicates
      
      let lastError: any = null
      
      for (const model of modelsToTry) {
        try {
          console.log(`Trying Venice AI image model: ${model}`)
          
          // Use the correct request body format for Venice AI
          const requestBody = {
            model: model,
            prompt: finalPrompt,
            hide_watermark: true,
            width: options?.width || 1024,
            height: options?.height || 1024
          }
          
          console.log('Sending request to Venice AI image/generate:', requestBody)
          
          const response = await fetch('https://api.venice.ai/api/v1/image/generate', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${this.config.apiKey}`,
            },
            body: JSON.stringify(requestBody)
          })

          console.log(`Venice AI Response status for model ${model}: ${response.status}`)
          
          if (response.ok) {
            const data = await response.json()
            console.log('Venice AI Response data structure:', Object.keys(data))
            console.log('Venice AI Full Response:', data)
            
            // Handle Venice AI response format - they use 'data' field with images array
            if (data.data && Array.isArray(data.data) && data.data.length > 0) {
              const imageData = data.data[0]
              console.log('Found data array, first image type:', typeof imageData)
              
              if (typeof imageData === 'string') {
                // Venice AI returns base64 strings
                const imageUrl = imageData.startsWith('data:') ? imageData : `data:image/png;base64,${imageData}`
                console.log(`Successfully generated image via Venice AI with model ${model}`)
                return imageUrl
              }
              
              // If it's an object, look for url or b64_json fields
              if (imageData && typeof imageData === 'object') {
                if (imageData.url) {
                  console.log(`Found image URL: ${imageData.url}`)
                  return imageData.url
                }
                if (imageData.b64_json) {
                  return `data:image/png;base64,${imageData.b64_json}`
                }
              }
            }
            
            // Fallback checks for other possible formats
            if (data.images && Array.isArray(data.images) && data.images.length > 0) {
              const imageData = data.images[0]
              if (typeof imageData === 'string') {
                const imageUrl = imageData.startsWith('data:') ? imageData : `data:image/png;base64,${imageData}`
                return imageUrl
              }
            }
            
            // Check for single image field
            if (data.image && typeof data.image === 'string') {
              const finalImage = data.image.startsWith('data:') ? data.image : `data:image/png;base64,${data.image}`
              return finalImage
            }
            
            // Check for url field
            if (data.url && typeof data.url === 'string') {
              return data.url
            }
            
            console.log(`No recognized image data in response for model ${model}, available fields:`, Object.keys(data))
            lastError = new Error(`No valid image data found in Venice AI response for model ${model}`)
            continue // Try next model
            
          } else {
            const errorText = await response.text()
            console.error(`Venice AI HTTP ${response.status} for model ${model}:`, errorText)
            lastError = new Error(`Venice AI API error for model ${model}: ${response.status} - ${errorText}`)
            
            // If it's a model not found error, try the next model
            if (response.status === 404 || errorText.includes('model not found') || errorText.includes('Specified model not found')) {
              console.log(`Model ${model} not found, trying next fallback...`)
              continue
            }
            
            // For other errors, try next model instead of throwing immediately
            console.log(`Error with model ${model}, trying next...`)
            continue
          }
        } catch (modelError) {
          console.error(`Error with model ${model}:`, modelError)
          lastError = modelError
          continue // Try next model
        }
      }
      
      // If all models failed, log the error and return placeholder
      console.log('All Venice AI image models failed, generating enhanced placeholder...')
      return this.generateAdvancedPlaceholder(prompt, options?.width || 400, options?.height || 400)
      
    } catch (error) {
      console.error('Venice AI image generation failed completely:', error)
      return this.generateAdvancedPlaceholder(prompt, options?.width || 400, options?.height || 400)
    } finally {
      this.semaphore.release()
    }
  }

  private generateAdvancedPlaceholder(prompt: string, width: number, height: number): string {
    // Generate a very sophisticated SVG-based portrait that looks more like an illustration
    const lowerPrompt = prompt.toLowerCase()
    console.log('Generating SVG placeholder for prompt:', lowerPrompt)
    
    // Determine character features
    let hairColor = '#4A4A4A' // Default dark brown
    let skinColor = '#F5DEB3' // Default natural skin tone 
    let outfitColor = '#6366f1' // Default indigo
    let eyeColor = '#8B4513' // Default brown eyes
    
    if (lowerPrompt.includes('blonde')) hairColor = '#FFD700'
    else if (lowerPrompt.includes('black hair') || lowerPrompt.includes('dark hair')) hairColor = '#1a1a1a'
    else if (lowerPrompt.includes('red hair') || lowerPrompt.includes('ginger')) hairColor = '#B22222'
    else if (lowerPrompt.includes('brown hair') || lowerPrompt.includes('brunette')) hairColor = '#654321'
    
    if (lowerPrompt.includes('tan skin')) skinColor = '#DEB887'
    else if (lowerPrompt.includes('dark skin')) skinColor = '#8D5524'
    else if (lowerPrompt.includes('pale skin')) skinColor = '#FFDBAC'
    
    if (lowerPrompt.includes('green eyes')) eyeColor = '#228B22'
    else if (lowerPrompt.includes('brown eyes')) eyeColor = '#8B4513'
    else if (lowerPrompt.includes('hazel eyes')) eyeColor = '#A0522D'
    
    // Generate style-based outfit  
    if (lowerPrompt.includes('goth') || lowerPrompt.includes('emo')) outfitColor = '#2F2F2F'
    else if (lowerPrompt.includes('cheerleader')) outfitColor = '#ef4444'
    else if (lowerPrompt.includes('business')) outfitColor = '#4A4A4A'
    
    console.log('SVG colors determined:', { hairColor, skinColor, outfitColor, eyeColor })
    
    const svg = `
      <svg width="${width}" height="${height}" xmlns="http://www.w3.org/2000/svg">
        <defs>
          <radialGradient id="bg" cx="50%" cy="30%" r="70%">
            <stop offset="0%" style="stop-color:rgba(100,100,120,0.1);stop-opacity:1" />
            <stop offset="100%" style="stop-color:rgba(60,60,80,0.3);stop-opacity:1" />
          </radialGradient>
          <linearGradient id="hair" x1="0%" y1="0%" x2="100%" y2="100%">
            <stop offset="0%" style="stop-color:${hairColor};stop-opacity:1" />
            <stop offset="100%" style="stop-color:${this.adjustBrightness(hairColor, -20)};stop-opacity:1" />
          </linearGradient>
          <linearGradient id="skin" x1="0%" y1="0%" x2="100%" y2="100%">
            <stop offset="0%" style="stop-color:${this.adjustBrightness(skinColor, 10)};stop-opacity:1" />
            <stop offset="100%" style="stop-color:${skinColor};stop-opacity:1" />
          </linearGradient>
          <linearGradient id="outfit" x1="0%" y1="0%" x2="100%" y2="100%">
            <stop offset="0%" style="stop-color:${this.adjustBrightness(outfitColor, 15)};stop-opacity:1" />
            <stop offset="100%" style="stop-color:${outfitColor};stop-opacity:1" />
          </linearGradient>
        </defs>
        
        <!-- Background -->
        <rect width="100%" height="100%" fill="#1a1a1a"/>
        
        <!-- Body/Shoulders -->
        <ellipse cx="${width/2}" cy="${height*0.85}" rx="${width*0.4}" ry="${height*0.2}" fill="url(#outfit)"/>
        
        <!-- Neck -->
        <rect x="${width/2 - width*0.05}" y="${height*0.6}" width="${width*0.1}" height="${height*0.15}" fill="url(#skin)"/>
        
        <!-- Head -->
        <ellipse cx="${width/2}" cy="${height*0.5}" rx="${width*0.18}" ry="${height*0.22}" fill="url(#skin)"/>
        
        <!-- Hair -->
        <ellipse cx="${width/2}" cy="${height*0.35}" rx="${width*0.22}" ry="${height*0.25}" fill="url(#hair)"/>
        
        <!-- Eyes -->
        <ellipse cx="${width/2 - width*0.07}" cy="${height*0.46}" rx="${width*0.02}" ry="${width*0.025}" fill="white"/>
        <ellipse cx="${width/2 + width*0.07}" cy="${height*0.46}" rx="${width*0.02}" ry="${width*0.025}" fill="white"/>
        <circle cx="${width/2 - width*0.07}" cy="${height*0.46}" r="${width*0.015}" fill="${eyeColor}"/>
        <circle cx="${width/2 + width*0.07}" cy="${height*0.46}" r="${width*0.015}" fill="${eyeColor}"/>
        <circle cx="${width/2 - width*0.065}" cy="${height*0.455}" r="${width*0.005}" fill="white"/>
        <circle cx="${width/2 + width*0.075}" cy="${height*0.455}" r="${width*0.005}" fill="white"/>
        
        <!-- Eyebrows -->
        <ellipse cx="${width/2 - width*0.07}" cy="${height*0.43}" rx="${width*0.025}" ry="${width*0.008}" fill="${this.adjustBrightness(hairColor, -30)}"/>
        <ellipse cx="${width/2 + width*0.07}" cy="${height*0.43}" rx="${width*0.025}" ry="${width*0.008}" fill="${this.adjustBrightness(hairColor, -30)}"/>
        
        <!-- Nose -->
        <ellipse cx="${width/2}" cy="${height*0.52}" rx="${width*0.008}" ry="${width*0.02}" fill="${this.adjustBrightness(skinColor, -10)}" opacity="0.6"/>
        
        <!-- Lips -->
        <ellipse cx="${width/2}" cy="${height*0.57}" rx="${width*0.025}" ry="${width*0.012}" fill="#FF69B4"/>
        
        <!-- Hair highlights -->
        <ellipse cx="${width/2 - width*0.1}" cy="${height*0.32}" rx="${width*0.03}" ry="${width*0.08}" fill="${this.adjustBrightness(hairColor, 30)}" opacity="0.4"/>
        <ellipse cx="${width/2 + width*0.08}" cy="${height*0.35}" rx="${width*0.025}" ry="${width*0.06}" fill="${this.adjustBrightness(hairColor, 30)}" opacity="0.4"/>
        
        <!-- Text overlay -->
        <text x="${width/2}" y="${height - 20}" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-family="Arial, sans-serif" font-size="12" font-weight="bold">Venice AI Unavailable - SVG Placeholder</text>
      </svg>
    `
    
    console.log('Generated SVG placeholder with outfit color:', outfitColor)
    return `data:image/svg+xml;base64,${btoa(svg)}`
  }
  
  private adjustBrightness(hex: string, percent: number): string {
    // Convert hex to RGB
    const num = parseInt(hex.replace("#", ""), 16);
    const amt = Math.round(2.55 * percent);
    const R = (num >> 16) + amt;
    const G = (num >> 8 & 0x00FF) + amt;
    const B = (num & 0x0000FF) + amt;
    return "#" + (0x1000000 + (R < 255 ? R < 1 ? 0 : R : 255) * 0x10000 +
      (G < 255 ? G < 1 ? 0 : G : 255) * 0x100 +
      (B < 255 ? B < 1 ? 0 : B : 255)).toString(16).slice(1);
  }

  private generatePlaceholderImage(prompt: string, width: number, height: number): string {
    // Generate a more detailed portrait-style placeholder based on the character description
    const canvas = document.createElement('canvas')
    canvas.width = width
    canvas.height = height
    const ctx = canvas.getContext('2d')!
    
    // Parse prompt for character features to determine colors
    const lowerPrompt = prompt.toLowerCase()
    
    // Determine hair color with more variety
    let hairColor = '#8B4513' // Default brown
    if (lowerPrompt.includes('blonde') || lowerPrompt.includes('golden')) hairColor = '#FFD700'
    else if (lowerPrompt.includes('black') || lowerPrompt.includes('dark hair')) hairColor = '#1a1a1a'
    else if (lowerPrompt.includes('red') || lowerPrompt.includes('ginger') || lowerPrompt.includes('auburn')) hairColor = '#B22222'
    else if (lowerPrompt.includes('silver') || lowerPrompt.includes('white') || lowerPrompt.includes('platinum')) hairColor = '#C0C0C0'
    else if (lowerPrompt.includes('pink')) hairColor = '#FF69B4'
    else if (lowerPrompt.includes('blue')) hairColor = '#4169E1'
    else if (lowerPrompt.includes('green')) hairColor = '#228B22'
    else if (lowerPrompt.includes('purple') || lowerPrompt.includes('violet')) hairColor = '#8A2BE2'
    else if (lowerPrompt.includes('brown') || lowerPrompt.includes('brunette')) hairColor = '#654321'
    else if (lowerPrompt.includes('light brown')) hairColor = '#A0522D'
    
    // Determine skin tone with more variety
    let skinColor = '#FDBCB4' // Default light
    if (lowerPrompt.includes('tan') || lowerPrompt.includes('olive')) skinColor = '#DEB887'
    else if (lowerPrompt.includes('dark skin') || lowerPrompt.includes('black')) skinColor = '#8D5524'
    else if (lowerPrompt.includes('pale') || lowerPrompt.includes('fair')) skinColor = '#FFDBAC'
    else if (lowerPrompt.includes('caramel') || lowerPrompt.includes('honey')) skinColor = '#D2B48C'
    else if (lowerPrompt.includes('ebony')) skinColor = '#704214'
    
    // Determine outfit color based on character type
    let outfitColor = '#FF1493' // Default pink
    if (lowerPrompt.includes('cheerleader')) outfitColor = '#FF4500'
    else if (lowerPrompt.includes('emo') || lowerPrompt.includes('goth')) outfitColor = '#2F2F2F'
    else if (lowerPrompt.includes('schoolgirl') || lowerPrompt.includes('uniform')) outfitColor = '#000080'
    else if (lowerPrompt.includes('casual')) outfitColor = '#87CEEB'
    else if (lowerPrompt.includes('business') || lowerPrompt.includes('professional')) outfitColor = '#4A4A4A'
    else if (lowerPrompt.includes('milf') || lowerPrompt.includes('mature')) outfitColor = '#8B0000'
    else if (lowerPrompt.includes('punk')) outfitColor = '#800080'
    else if (lowerPrompt.includes('nerd') || lowerPrompt.includes('bookworm')) outfitColor = '#228B22'
    
    // Create gradient background based on personality
    const bgGradient = ctx.createRadialGradient(width/2, height/3, 0, width/2, height/3, width/2)
    if (lowerPrompt.includes('shy') || lowerPrompt.includes('innocent')) {
      bgGradient.addColorStop(0, 'rgba(255, 182, 193, 0.2)')
      bgGradient.addColorStop(1, 'rgba(176, 224, 230, 0.3)')
    } else if (lowerPrompt.includes('wild') || lowerPrompt.includes('bold')) {
      bgGradient.addColorStop(0, 'rgba(255, 69, 0, 0.2)')
      bgGradient.addColorStop(1, 'rgba(255, 20, 147, 0.3)')
    } else if (lowerPrompt.includes('goth') || lowerPrompt.includes('emo')) {
      bgGradient.addColorStop(0, 'rgba(75, 0, 130, 0.2)')
      bgGradient.addColorStop(1, 'rgba(0, 0, 0, 0.4)')
    } else {
      bgGradient.addColorStop(0, 'rgba(255, 255, 255, 0.1)')
      bgGradient.addColorStop(1, 'rgba(0, 0, 0, 0.3)')
    }
    ctx.fillStyle = bgGradient
    ctx.fillRect(0, 0, width, height)
    
    // Draw improved portrait silhouette
    const centerX = width / 2
    const centerY = height * 0.6
    
    // Body/shoulders with more shape variation
    ctx.fillStyle = outfitColor
    ctx.beginPath()
    if (lowerPrompt.includes('milf') || lowerPrompt.includes('mature')) {
      ctx.ellipse(centerX, centerY + height * 0.25, width * 0.45, height * 0.22, 0, 0, Math.PI * 2)
    } else {
      ctx.ellipse(centerX, centerY + height * 0.25, width * 0.4, height * 0.2, 0, 0, Math.PI * 2)
    }
    ctx.fill()
    
    // Add outfit details
    if (lowerPrompt.includes('cheerleader')) {
      ctx.fillStyle = '#FFFFFF'
      ctx.fillRect(centerX - width * 0.03, centerY + height * 0.15, width * 0.06, height * 0.1)
    } else if (lowerPrompt.includes('business')) {
      ctx.strokeStyle = '#FFFFFF'
      ctx.lineWidth = 2
      ctx.beginPath()
      ctx.moveTo(centerX - width * 0.1, centerY + height * 0.1)
      ctx.lineTo(centerX + width * 0.1, centerY + height * 0.1)
      ctx.stroke()
    }
    
    // Neck
    ctx.fillStyle = skinColor
    ctx.fillRect(centerX - width * 0.05, centerY, width * 0.1, height * 0.15)
    
    // Head with more shape variation
    ctx.beginPath()
    if (lowerPrompt.includes('mature') || lowerPrompt.includes('milf')) {
      ctx.ellipse(centerX, centerY - height * 0.1, width * 0.19, height * 0.23, 0, 0, Math.PI * 2)
    } else {
      ctx.ellipse(centerX, centerY - height * 0.1, width * 0.18, height * 0.22, 0, 0, Math.PI * 2)
    }
    ctx.fill()
    
    // Hair with style variations
    ctx.fillStyle = hairColor
    ctx.beginPath()
    if (lowerPrompt.includes('long') || lowerPrompt.includes('flowing')) {
      // Long hair
      ctx.ellipse(centerX, centerY - height * 0.15, width * 0.25, height * 0.25, 0, 0, Math.PI * 2)
    } else if (lowerPrompt.includes('short') || lowerPrompt.includes('pixie')) {
      // Short hair
      ctx.ellipse(centerX, centerY - height * 0.2, width * 0.2, height * 0.18, 0, 0, Math.PI * 2)
    } else if (lowerPrompt.includes('punk') || lowerPrompt.includes('mohawk')) {
      // Punk style
      ctx.rect(centerX - width * 0.05, centerY - height * 0.35, width * 0.1, height * 0.15)
    } else {
      // Medium hair
      ctx.ellipse(centerX, centerY - height * 0.2, width * 0.22, height * 0.2, 0, 0, Math.PI * 2)
    }
    ctx.fill()
    
    // Add hair highlights and texture
    ctx.fillStyle = hairColor + '60' // Semi-transparent
    for (let i = 0; i < 20; i++) {
      const x = centerX + (Math.random() - 0.5) * width * 0.4
      const y = centerY - height * 0.35 + Math.random() * height * 0.3
      const size = Math.random() * 6 + 1
      ctx.beginPath()
      ctx.arc(x, y, size, 0, Math.PI * 2)
      ctx.fill()
    }
    
    // Eyes with more expression
    const eyeSize = width * 0.025
    ctx.fillStyle = '#2F2F2F'
    ctx.beginPath()
    ctx.arc(centerX - width * 0.07, centerY - height * 0.12, eyeSize, 0, Math.PI * 2)
    ctx.fill()
    ctx.beginPath()
    ctx.arc(centerX + width * 0.07, centerY - height * 0.12, eyeSize, 0, Math.PI * 2)
    ctx.fill()
    
    // Eye highlights
    ctx.fillStyle = '#FFFFFF'
    ctx.beginPath()
    ctx.arc(centerX - width * 0.065, centerY - height * 0.125, width * 0.008, 0, Math.PI * 2)
    ctx.fill()
    ctx.beginPath()
    ctx.arc(centerX + width * 0.075, centerY - height * 0.125, width * 0.008, 0, Math.PI * 2)
    ctx.fill()
    
    // Eyebrows
    ctx.strokeStyle = hairColor
    ctx.lineWidth = 2
    ctx.beginPath()
    ctx.moveTo(centerX - width * 0.09, centerY - height * 0.15)
    ctx.lineTo(centerX - width * 0.05, centerY - height * 0.145)
    ctx.stroke()
    ctx.beginPath()
    ctx.moveTo(centerX + width * 0.05, centerY - height * 0.145)
    ctx.lineTo(centerX + width * 0.09, centerY - height * 0.15)
    ctx.stroke()
    
    // Lips with style variation
    ctx.fillStyle = '#FF69B4'
    if (lowerPrompt.includes('goth') || lowerPrompt.includes('emo')) {
      ctx.fillStyle = '#800080'
    } else if (lowerPrompt.includes('natural') || lowerPrompt.includes('innocent')) {
      ctx.fillStyle = '#FFB6C1'
    }
    ctx.beginPath()
    ctx.ellipse(centerX, centerY - height * 0.05, width * 0.025, width * 0.015, 0, 0, Math.PI * 2)
    ctx.fill()
    
    // Add personality-based accessories
    if (lowerPrompt.includes('nerd') || lowerPrompt.includes('bookworm')) {
      // Glasses
      ctx.strokeStyle = '#2F2F2F'
      ctx.lineWidth = 2
      ctx.beginPath()
      ctx.arc(centerX - width * 0.07, centerY - height * 0.12, width * 0.04, 0, Math.PI * 2)
      ctx.stroke()
      ctx.beginPath()
      ctx.arc(centerX + width * 0.07, centerY - height * 0.12, width * 0.04, 0, Math.PI * 2)
      ctx.stroke()
      ctx.beginPath()
      ctx.moveTo(centerX - width * 0.03, centerY - height * 0.12)
      ctx.lineTo(centerX + width * 0.03, centerY - height * 0.12)
      ctx.stroke()
    }
    
    if (lowerPrompt.includes('punk') || lowerPrompt.includes('rebel')) {
      // Earrings
      ctx.fillStyle = '#C0C0C0'
      ctx.beginPath()
      ctx.arc(centerX - width * 0.12, centerY - height * 0.08, width * 0.01, 0, Math.PI * 2)
      ctx.fill()
      ctx.beginPath()
      ctx.arc(centerX + width * 0.12, centerY - height * 0.08, width * 0.01, 0, Math.PI * 2)
      ctx.fill()
    }
    
    return canvas.toDataURL()
  }
}

export const aiService = AIService.getInstance()